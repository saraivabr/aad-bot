/**
 * CONVERSATION ORCHESTRATOR v2.0
 *
 * Orquestra toda a experi√™ncia conversacional integrando:
 * - ConversationalEngine (processamento principal)
 * - SemanticMemoryStore (mem√≥ria de longo prazo)
 * - VoiceIntelligence (processamento de √°udio)
 * - MediaService (gera√ß√£o de m√≠dia)
 * - ClientService (persist√™ncia de dados)
 *
 * Features:
 * - Processamento unificado de mensagens
 * - Respostas adaptativas (texto/√°udio/h√≠brido)
 * - Fragmenta√ß√£o natural de mensagens
 * - Timing humanizado
 * - Proactive engagement
 * - Smart message buffering
 */

const conversationalEngine = require('./conversationalEngine');
const { SemanticMemoryStore, MEMORY_TYPES, IMPORTANCE_LEVELS } = require('./semanticMemory');
const clientService = require('../services/clientService');

// Lazy load services that require API keys
let voiceIntelligence = null;
let mediaService = null;

function getVoiceIntelligence() {
    if (!voiceIntelligence) {
        voiceIntelligence = require('../services/voiceIntelligence');
    }
    return voiceIntelligence;
}

function getMediaService() {
    if (!mediaService) {
        mediaService = require('../services/mediaService');
    }
    return mediaService;
}

// ============================================
// RESPONSE FORMATTER
// ============================================

class ResponseFormatter {
    constructor() {
        this.fragmentPatterns = {
            // Pontos naturais de quebra
            naturalBreaks: [
                /([.!?])\s+(?=[A-Z√Ä-√ö])/g,  // Fim de frase seguido de mai√∫scula
                /(<SPLIT>)/g,                 // Tag expl√≠cita
            ],
            // Padr√µes que N√ÉO devem ser quebrados
            keepTogether: [
                /https?:\/\/\S+/g,            // URLs
                /\d+[.,]\d+/g,                // N√∫meros decimais
            ]
        };
    }

    /**
     * Fragmenta resposta em mensagens naturais
     */
    fragment(text, maxFragments = 4) {
        // Primeiro, processa <SPLIT> expl√≠citos
        if (text.includes('<SPLIT>')) {
            return text
                .split('<SPLIT>')
                .map(f => f.trim())
                .filter(f => f.length > 0)
                .slice(0, maxFragments);
        }

        // Fragmenta√ß√£o autom√°tica baseada em pontua√ß√£o
        const sentences = text.split(/(?<=[.!?])\s+/);

        if (sentences.length <= 2) {
            return [text]; // Mensagem curta, n√£o fragmentar
        }

        // Agrupar senten√ßas em fragmentos l√≥gicos
        const fragments = [];
        let currentFragment = '';

        for (const sentence of sentences) {
            // Se adicionar a senten√ßa deixar muito longo, criar novo fragmento
            if (currentFragment.length + sentence.length > 200 && currentFragment.length > 0) {
                fragments.push(currentFragment.trim());
                currentFragment = sentence;
            } else {
                currentFragment += (currentFragment ? ' ' : '') + sentence;
            }

            // Limite de fragmentos
            if (fragments.length >= maxFragments - 1) {
                break;
            }
        }

        if (currentFragment) {
            fragments.push(currentFragment.trim());
        }

        return fragments.slice(0, maxFragments);
    }

    /**
     * Calcula tempo de digita√ß√£o humanizado
     */
    calculateTypingTime(text, userPace = 'normal') {
        const baseSpeed = {
            fast: 20,     // 20ms por caractere
            normal: 35,   // 35ms por caractere
            slow: 50      // 50ms por caractere
        }[userPace] || 35;

        const baseTime = text.length * baseSpeed;

        // Adicionar varia√ß√£o aleat√≥ria (¬±20%)
        const variation = baseTime * 0.2 * (Math.random() - 0.5);

        // Limites: min 800ms, max 4000ms
        return Math.min(Math.max(baseTime + variation, 800), 4000);
    }

    /**
     * Calcula delay entre mensagens
     */
    calculateInterMessageDelay() {
        // Entre 300ms e 800ms, distribui√ß√£o natural
        return 300 + Math.random() * 500;
    }

    /**
     * Remove formata√ß√£o para TTS
     */
    prepareForTTS(text) {
        return text
            .replace(/<SPLIT>/g, '... ')
            .replace(/<REACT:.*?>/g, '')
            .replace(/\|\|.*?\|\|/g, '')
            .replace(/[üî•üí™üöÄüéâüëè‚úåÔ∏èüëãüò§üí≠ü§îüíú‚ù§Ô∏èüôè‚ö°üí°üëÄ‚ú®üòäü§ó]/g, '')
            .replace(/\*\*/g, '')
            .replace(/\n+/g, '. ')
            .trim();
    }
}

// ============================================
// MESSAGE BUFFER
// ============================================

class MessageBuffer {
    constructor() {
        this.buffers = new Map(); // chatId -> { messages: [], timer: timeout, voiceContext: {} }
        this.bufferTimeout = 3500; // 3.5 segundos
    }

    add(chatId, message, voiceContext = null) {
        if (!this.buffers.has(chatId)) {
            this.buffers.set(chatId, {
                messages: [],
                timer: null,
                voiceContext: null,
                firstMessageTime: Date.now()
            });
        }

        const buffer = this.buffers.get(chatId);

        // Limpar timer anterior
        if (buffer.timer) {
            clearTimeout(buffer.timer);
        }

        // Adicionar mensagem
        buffer.messages.push(message);

        // Atualizar contexto de voz se presente
        if (voiceContext) {
            buffer.voiceContext = voiceContext;
        }

        return buffer;
    }

    setCallback(chatId, callback) {
        const buffer = this.buffers.get(chatId);
        if (!buffer) return;

        buffer.timer = setTimeout(async () => {
            const fullMessage = buffer.messages.join(' ').trim();
            const voiceContext = buffer.voiceContext;

            // Limpar buffer
            this.buffers.delete(chatId);

            // Executar callback
            await callback(fullMessage, voiceContext);
        }, this.bufferTimeout);
    }

    getCombinedMessage(chatId) {
        const buffer = this.buffers.get(chatId);
        if (!buffer) return null;

        return {
            text: buffer.messages.join(' ').trim(),
            voiceContext: buffer.voiceContext,
            messageCount: buffer.messages.length,
            timeSinceFirst: Date.now() - buffer.firstMessageTime
        };
    }

    clear(chatId) {
        const buffer = this.buffers.get(chatId);
        if (buffer?.timer) {
            clearTimeout(buffer.timer);
        }
        this.buffers.delete(chatId);
    }
}

// ============================================
// MAIN ORCHESTRATOR
// ============================================

class ConversationOrchestrator {
    constructor() {
        this.formatter = new ResponseFormatter();
        this.buffer = new MessageBuffer();
        this.processingChats = new Set(); // Evita processamento duplicado
    }

    /**
     * Processa uma mensagem de entrada
     * Retorna um objeto com instru√ß√µes de resposta
     */
    async processMessage(messageObj, chatId) {
        // Evitar processamento duplicado
        if (this.processingChats.has(chatId)) {
            console.log(`[Orchestrator] Chat ${chatId} already processing, buffering...`);
            return null;
        }

        try {
            this.processingChats.add(chatId);

            // 1. Extrair dados da mensagem
            const messageData = await this.extractMessageData(messageObj);

            // 2. Processar com o engine
            const result = await conversationalEngine.processMessage(
                chatId,
                messageData.text,
                messageData.voiceContext,
                messageData.contactName
            );

            // 3. Armazenar mem√≥rias sem√¢nticas
            await this.storeMemories(chatId, messageData.text, result.state);

            // 4. Sincronizar dados do cliente
            this.syncClientData(chatId, result.state.userProfile);

            // 5. Preparar resposta formatada
            const response = await this.prepareResponse(result, messageData, chatId);

            return response;

        } finally {
            this.processingChats.delete(chatId);
        }
    }

    /**
     * Extrai dados da mensagem (texto, m√≠dia, contexto)
     */
    async extractMessageData(messageObj) {
        let text = messageObj.body?.trim() || '';
        let voiceContext = null;
        let contactName = null;

        // Obter nome do contato
        try {
            const contact = await messageObj.getContact();
            contactName = contact?.pushname || contact?.name || null;
        } catch (e) {
            console.log("[Orchestrator] Could not get contact name");
        }

        // Processar m√≠dia se presente
        if (messageObj.hasMedia) {
            try {
                const media = await messageObj.downloadMedia();

                if (media.mimetype.startsWith('audio/') || messageObj.type === 'ptt') {
                    // √Åudio -> Transcri√ß√£o + An√°lise
                    voiceContext = await getVoiceIntelligence().transcribeWithContext(media);
                    text = voiceContext.text;
                    getVoiceIntelligence().recordAudioReceived(messageObj.from);

                } else if (media.mimetype.startsWith('image/')) {
                    // Imagem -> Descri√ß√£o
                    const description = await getMediaService().describeImage(media);
                    text = `[Imagem recebida]: ${description}`;
                }
            } catch (e) {
                console.error("[Orchestrator] Media processing error:", e.message);
            }
        }

        return { text, voiceContext, contactName };
    }

    /**
     * Armazena mem√≥rias relevantes da intera√ß√£o
     */
    async storeMemories(chatId, message, state) {
        try {
            // Extra√ß√£o autom√°tica de mem√≥rias
            await SemanticMemoryStore.extractAndStore(chatId, message, {
                emotion: state.emotionalState.primary,
                intensity: state.emotionalState.intensity
            });

            // Armazenar se houve conquista
            if (state.currentIntent?.primary?.intent === 'share_achievement') {
                await SemanticMemoryStore.store(
                    chatId,
                    `Conquista compartilhada: ${message.substring(0, 100)}`,
                    {
                        type: MEMORY_TYPES.EPISODIC,
                        importance: IMPORTANCE_LEVELS.HIGH,
                        emotion: 'excited'
                    }
                );
            }

        } catch (e) {
            console.error("[Orchestrator] Memory storage error:", e.message);
        }
    }

    /**
     * Sincroniza dados do userProfile com clientService
     */
    syncClientData(chatId, userProfile) {
        const updates = {};

        if (userProfile.name) updates.name = userProfile.name;
        if (userProfile.business) updates.businessName = userProfile.business;
        if (userProfile.niche) updates.niche = userProfile.niche;
        if (userProfile.location) updates.location = userProfile.location;

        if (Object.keys(updates).length > 0) {
            clientService.updateClient(chatId, updates);
        }
    }

    /**
     * Prepara a resposta formatada para envio
     */
    async prepareResponse(result, messageData, chatId) {
        const { response, actions, reaction, state, metadata } = result;

        // 1. Fragmentar resposta
        const fragments = this.formatter.fragment(response);

        // 2. Calcular timings
        const timings = fragments.map(f => ({
            text: f,
            typingTime: this.formatter.calculateTypingTime(f),
            interDelay: this.formatter.calculateInterMessageDelay()
        }));

        // 3. Determinar se deve responder com √°udio
        const shouldUseAudio = this.shouldRespondWithAudio(messageData, state);

        // 4. Preparar √°udio se necess√°rio
        let audioResponse = null;
        if (shouldUseAudio) {
            const textForTTS = this.formatter.prepareForTTS(response);
            audioResponse = {
                text: textForTTS,
                emotion: state.emotionalState.primary,
                persona: state.activePersona
            };
        }

        // 5. Processar a√ß√µes especiais
        const mediaActions = await this.processActions(actions);

        // 6. Construir resposta final
        return {
            type: shouldUseAudio ? 'hybrid' : 'text',
            fragments: timings,
            audio: audioResponse,
            reaction: reaction,
            mediaActions,
            metadata: {
                ...metadata,
                shouldSendTyping: true,
                shouldSendRecording: shouldUseAudio
            }
        };
    }

    /**
     * Determina se deve responder com √°udio
     */
    shouldRespondWithAudio(messageData, state) {
        // Se veio de √°udio e contexto sugere
        if (messageData.voiceContext?.shouldRespondWithAudio) {
            return true;
        }

        // Se usu√°rio prefere √°udio (baseado em hist√≥rico)
        if (state.userProfile.responsePreference === 'audio') {
            return true;
        }

        // N√£o responder com √°udio se n√£o tiver API key
        if (!process.env.OPENAI_API_KEY) {
            return false;
        }

        // Se emo√ß√£o √© intensa e negativa (empatia via voz)
        if (['sad', 'frustrated'].includes(state.emotionalState.primary) &&
            state.emotionalState.intensity > 0.6) {
            return true;
        }

        return false;
    }

    /**
     * Processa a√ß√µes especiais (imagem, √°udio, etc)
     */
    async processActions(actions) {
        const mediaActions = [];

        for (const action of actions) {
            switch (action.type) {
                case 'generate_image':
                    mediaActions.push({
                        type: 'image',
                        promise: getMediaService().generateImage(action.prompt),
                        caption: 't√° na m√£o üçå'
                    });
                    break;

                case 'send_audio':
                    mediaActions.push({
                        type: 'audio',
                        promise: getMediaService().textToSpeech(action.text)
                    });
                    break;

                case 'save':
                    // J√° processado pelo engine
                    break;
            }
        }

        return mediaActions;
    }

    /**
     * Executa o envio da resposta via WhatsApp
     * Esta fun√ß√£o √© chamada pelo commandDispatcher
     */
    async executeResponse(messageObj, response) {
        const chat = await messageObj.getChat();
        const delay = (ms) => new Promise(resolve => setTimeout(resolve, ms));

        // 1. Enviar rea√ß√£o se sugerida
        if (response.reaction) {
            try {
                await messageObj.react(response.reaction);
            } catch (e) {
                console.log("[Orchestrator] Reaction failed:", e.message);
            }
        }

        // 2. Enviar fragmentos de texto
        for (const [index, fragment] of response.fragments.entries()) {
            // Mostrar "digitando..."
            if (response.metadata.shouldSendTyping) {
                await chat.sendStateTyping();
            }

            // Aguardar tempo de digita√ß√£o
            await delay(fragment.typingTime);

            // Enviar mensagem
            if (index === 0) {
                await messageObj.reply(fragment.text);
            } else {
                await chat.sendMessage(fragment.text);
            }

            // Delay entre mensagens
            if (index < response.fragments.length - 1) {
                await delay(fragment.interDelay);
            }
        }

        // 3. Enviar √°udio se necess√°rio
        if (response.audio) {
            await delay(800);
            await chat.sendRecordingState();

            const audioMedia = await getVoiceIntelligence().generateVoiceResponse(
                response.audio.text,
                response.audio.emotion,
                response.audio.persona
            );

            if (audioMedia) {
                await delay(1500);
                await chat.sendMessage(audioMedia, { sendAudioAsVoice: true });
            }
        }

        // 4. Enviar m√≠dia gerada
        for (const action of response.mediaActions) {
            await delay(500);

            if (action.type === 'image') {
                await chat.sendStateTyping();
                const media = await action.promise;
                if (media) {
                    await chat.sendMessage(media, { caption: action.caption });
                }
            } else if (action.type === 'audio') {
                await chat.sendRecordingState();
                const media = await action.promise;
                if (media) {
                    await chat.sendMessage(media, { sendAudioAsVoice: true });
                }
            }
        }
    }

    /**
     * Obt√©m estat√≠sticas do chat
     */
    getStats(chatId) {
        const engineStats = conversationalEngine.getStats(chatId);
        const memoryStats = SemanticMemoryStore.summarize(chatId);

        return {
            ...engineStats,
            memory: memoryStats
        };
    }

    /**
     * Reseta um chat completamente
     */
    resetChat(chatId) {
        conversationalEngine.resetChat(chatId);
        SemanticMemoryStore.forgetAll(chatId);
        this.buffer.clear(chatId);
    }
}

module.exports = new ConversationOrchestrator();
